#!/usr/bin/env python3
"""
·ª®ng d·ª•ng ph√¢n t√≠ch ƒë·ªô tu·ªïi t·ª´ khu√¥n m·∫∑t
"""

import cv2
import numpy as np
import os
from datetime import datetime

class AgeAnalyzer:
    def __init__(self):
        """Kh·ªüi t·∫°o b·ªô ph√¢n t√≠ch tu·ªïi"""
        # Load face detector
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # ƒê·ªãnh nghƒ©a c√°c nh√≥m tu·ªïi
        self.age_groups = {
            0: 'Tr·∫ª s∆° sinh (0-2 tu·ªïi)',
            1: 'Tr·∫ª nh·ªè (3-6 tu·ªïi)', 
            2: 'Tr·∫ª em (7-12 tu·ªïi)',
            3: 'Thi·∫øu ni√™n (13-17 tu·ªïi)',
            4: 'Thanh ni√™n (18-25 tu·ªïi)',
            5: 'Ng∆∞·ªùi tr∆∞·ªüng th√†nh (26-35 tu·ªïi)',
            6: 'Trung ni√™n (36-50 tu·ªïi)',
            7: 'Cao tu·ªïi (51-65 tu·ªïi)',
            8: 'Ng∆∞·ªùi gi√† (65+ tu·ªïi)'
        }
        
        # M√†u s·∫Øc cho t·ª´ng nh√≥m tu·ªïi
        self.age_colors = {
            0: (255, 192, 203),  # Pink - Tr·∫ª s∆° sinh
            1: (255, 165, 0),    # Orange - Tr·∫ª nh·ªè
            2: (255, 255, 0),    # Yellow - Tr·∫ª em
            3: (0, 255, 255),    # Cyan - Thi·∫øu ni√™n
            4: (0, 255, 0),      # Green - Thanh ni√™n
            5: (0, 128, 255),    # Blue - Tr∆∞·ªüng th√†nh
            6: (128, 0, 255),    # Purple - Trung ni√™n
            7: (255, 0, 128),    # Magenta - Cao tu·ªïi
            8: (128, 128, 128)   # Gray - Ng∆∞·ªùi gi√†
        }
    
    def analyze_face_features(self, face_region):
        """Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t ƒë·ªÉ ∆∞·ªõc t√≠nh tu·ªïi"""
        gray_face = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
        h, w = gray_face.shape
        
        features = {}
        
        # 1. Ph√¢n t√≠ch k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
        face_area = h * w
        features['face_area'] = face_area
        features['width'] = w
        features['height'] = h
        features['aspect_ratio'] = w / h if h > 0 else 1
        
        # 2. Ph√¢n t√≠ch texture (ƒë·ªô nh√°m da)
        laplacian = cv2.Laplacian(gray_face, cv2.CV_64F)
        features['texture_variance'] = laplacian.var()
        
        # 3. Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ph·∫£n
        features['contrast'] = gray_face.std()
        
        # 4. Ph√¢n t√≠ch histogram (ph√¢n b·ªë ƒë·ªô s√°ng)
        hist = cv2.calcHist([gray_face], [0], None, [256], [0, 256])
        features['hist_mean'] = np.mean(hist)
        features['hist_std'] = np.std(hist)
        
        # 5. Ph√¢n t√≠ch c·∫°nh (n·∫øp nhƒÉn)
        edges = cv2.Canny(gray_face, 50, 150)
        features['edge_density'] = np.sum(edges > 0) / (h * w)
        
        # 6. Ph√¢n t√≠ch gradient (ƒë·ªô thay ƒë·ªïi c∆∞·ªùng ƒë·ªô)
        grad_x = cv2.Sobel(gray_face, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray_face, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        features['gradient_mean'] = np.mean(gradient_magnitude)
        
        # 7. Ph√¢n t√≠ch ƒë·ªô m·ªãn da
        blur = cv2.GaussianBlur(gray_face, (5, 5), 0)
        features['smoothness'] = np.mean(np.abs(gray_face.astype(float) - blur.astype(float)))
        
        return features
    
    def estimate_age_group(self, features):
        """∆Ø·ªõc t√≠nh nh√≥m tu·ªïi d·ª±a tr√™n ƒë·∫∑c tr∆∞ng"""
        score = 0
        confidence = 0
        
        # Ph√¢n t√≠ch k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
        face_area = features['face_area']
        if face_area < 3000:
            score += 3  # R·∫•t nh·ªè - tr·∫ª s∆° sinh/tr·∫ª nh·ªè
            confidence += 0.8
        elif face_area < 6000:
            score += 2  # Nh·ªè - tr·∫ª em
            confidence += 0.7
        elif face_area < 12000:
            score += 1  # Trung b√¨nh - thi·∫øu ni√™n/thanh ni√™n
            confidence += 0.6
        elif face_area > 20000:
            score -= 1  # L·ªõn - ng∆∞·ªùi l·ªõn
            confidence += 0.5
        
        # Ph√¢n t√≠ch texture (da m·ªãn = tr·∫ª, da nhƒÉn = gi√†)
        texture = features['texture_variance']
        if texture > 800:
            score += 2  # Da r·∫•t m·ªãn
            confidence += 0.7
        elif texture > 400:
            score += 1  # Da m·ªãn
            confidence += 0.6
        elif texture < 100:
            score -= 2  # Da nhƒÉn nhi·ªÅu
            confidence += 0.8
        elif texture < 200:
            score -= 1  # Da c√≥ n·∫øp nhƒÉn
            confidence += 0.6
        
        # Ph√¢n t√≠ch ƒë·ªô t∆∞∆°ng ph·∫£n
        contrast = features['contrast']
        if contrast > 60:
            score += 1  # T∆∞∆°ng ph·∫£n cao = da tr·∫ª
            confidence += 0.5
        elif contrast < 30:
            score -= 1  # T∆∞∆°ng ph·∫£n th·∫•p = da gi√†
            confidence += 0.5
        
        # Ph√¢n t√≠ch m·∫≠t ƒë·ªô c·∫°nh (n·∫øp nhƒÉn)
        edge_density = features['edge_density']
        if edge_density < 0.05:
            score += 2  # √çt n·∫øp nhƒÉn = tr·∫ª
            confidence += 0.7
        elif edge_density < 0.1:
            score += 1
            confidence += 0.5
        elif edge_density > 0.2:
            score -= 2  # Nhi·ªÅu n·∫øp nhƒÉn = gi√†
            confidence += 0.8
        elif edge_density > 0.15:
            score -= 1
            confidence += 0.6
        
        # Ph√¢n t√≠ch ƒë·ªô m·ªãn da
        smoothness = features['smoothness']
        if smoothness < 5:
            score += 2  # Da r·∫•t m·ªãn
            confidence += 0.6
        elif smoothness < 10:
            score += 1  # Da m·ªãn
            confidence += 0.4
        elif smoothness > 20:
            score -= 1  # Da kh√¥ng m·ªãn
            confidence += 0.4
        
        # Ph√¢n t√≠ch gradient
        gradient = features['gradient_mean']
        if gradient < 15:
            score += 1  # Gradient th·∫•p = da m·ªãn
            confidence += 0.3
        elif gradient > 30:
            score -= 1  # Gradient cao = da nhƒÉn
            confidence += 0.3
        
        # T√≠nh confidence trung b√¨nh
        confidence = min(confidence / 6, 1.0)
        
        # Quy·∫øt ƒë·ªãnh nh√≥m tu·ªïi d·ª±a tr√™n score
        if score >= 8:
            return 0, confidence  # Tr·∫ª s∆° sinh
        elif score >= 6:
            return 1, confidence  # Tr·∫ª nh·ªè
        elif score >= 4:
            return 2, confidence  # Tr·∫ª em
        elif score >= 2:
            return 3, confidence  # Thi·∫øu ni√™n
        elif score >= 0:
            return 4, confidence  # Thanh ni√™n
        elif score >= -2:
            return 5, confidence  # Tr∆∞·ªüng th√†nh
        elif score >= -4:
            return 6, confidence  # Trung ni√™n
        elif score >= -6:
            return 7, confidence  # Cao tu·ªïi
        else:
            return 8, confidence  # Ng∆∞·ªùi gi√†
    
    def analyze_image(self, image_path):
        """Ph√¢n t√≠ch ·∫£nh v√† ∆∞·ªõc t√≠nh tu·ªïi"""
        # ƒê·ªçc ·∫£nh
        image = cv2.imread(image_path)
        if image is None:
            print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh!")
            return None
        
        # Ph√°t hi·ªán khu√¥n m·∫∑t
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(
            gray, 
            scaleFactor=1.1, 
            minNeighbors=5, 
            minSize=(50, 50),
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        if len(faces) == 0:
            print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o!")
            return None
        
        results = []
        result_image = image.copy()
        
        print(f"\nüîç Ph√¢n t√≠ch {len(faces)} khu√¥n m·∫∑t:")
        print("=" * 50)
        
        for i, (x, y, w, h) in enumerate(faces):
            print(f"\nüë§ Khu√¥n m·∫∑t {i+1}:")
            
            # C·∫Øt v√πng khu√¥n m·∫∑t
            face_region = image[y:y+h, x:x+w]
            
            # Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng
            features = self.analyze_face_features(face_region)
            
            # ∆Ø·ªõc t√≠nh tu·ªïi
            age_group_id, confidence = self.estimate_age_group(features)
            age_group_name = self.age_groups[age_group_id]
            color = self.age_colors[age_group_id]
            
            # In th√¥ng tin chi ti·∫øt
            print(f"   üéÇ ƒê·ªô tu·ªïi ∆∞·ªõc t√≠nh: {age_group_name}")
            print(f"   üìä ƒê·ªô tin c·∫≠y: {confidence:.1%}")
            print(f"   üìè K√≠ch th∆∞·ªõc: {w}x{h} pixels")
            print(f"   üìê Di·ªán t√≠ch: {features['face_area']} pixels")
            print(f"   üé® Texture: {features['texture_variance']:.1f}")
            print(f"   üåü Contrast: {features['contrast']:.1f}")
            print(f"   üìà Edge density: {features['edge_density']:.3f}")
            print(f"   ‚ú® Smoothness: {features['smoothness']:.1f}")
            
            # V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh
            cv2.rectangle(result_image, (x, y), (x+w, y+h), color, 2)
            
            # V·∫Ω nh√£n tu·ªïi
            label = f"{age_group_name}"
            confidence_text = f"({confidence:.0%})"
            
            # T√≠nh k√≠ch th∆∞·ªõc text
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.5
            thickness = 1
            
            (label_w, label_h), _ = cv2.getTextSize(label, font, font_scale, thickness)
            (conf_w, conf_h), _ = cv2.getTextSize(confidence_text, font, font_scale, thickness)
            
            # V·∫Ω background cho text
            cv2.rectangle(result_image, (x, y-35), (x + max(label_w, conf_w) + 10, y), color, -1)
            
            # V·∫Ω text
            cv2.putText(result_image, label, (x+5, y-20), font, font_scale, (255, 255, 255), thickness)
            cv2.putText(result_image, confidence_text, (x+5, y-5), font, font_scale, (255, 255, 255), thickness)
            
            # L∆∞u th√¥ng tin
            results.append({
                'id': i+1,
                'bbox': (x, y, w, h),
                'age_group': age_group_name,
                'age_id': age_group_id,
                'confidence': confidence,
                'features': features
            })
        
        return result_image, results
    
    def capture_and_analyze(self):
        """Ch·ª•p ·∫£nh t·ª´ camera v√† ph√¢n t√≠ch"""
        print("üì∏ Ch·ª•p ·∫£nh v√† Ph√¢n t√≠ch Tu·ªïi")
        print("=" * 40)
        
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("‚ùå Kh√¥ng th·ªÉ m·ªü camera!")
            return
        
        print("‚úÖ Camera ƒë√£ s·∫µn s√†ng!")
        print("üí° Nh·∫•n SPACE ƒë·ªÉ ch·ª•p ·∫£nh, ESC ƒë·ªÉ tho√°t")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # Ph√°t hi·ªán khu√¥n m·∫∑t real-time
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(50, 50))
            
            # V·∫Ω khung khu√¥n m·∫∑t
            display_frame = frame.copy()
            for (x, y, w, h) in faces:
                cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(display_frame, 'Face Ready', (x, y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n
            cv2.putText(display_frame, f"Faces: {len(faces)} | SPACE: Capture | ESC: Exit", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.imshow('Age Analysis - Capture', display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            if key == 32:  # SPACE
                # Ch·ª•p ·∫£nh
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"age_photo_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                
                print(f"\nüì∏ ƒê√£ ch·ª•p ·∫£nh: {filename}")
                
                # Ph√¢n t√≠ch ·∫£nh
                result_image, results = self.analyze_image(filename)
                
                if results:
                    # L∆∞u ·∫£nh k·∫øt qu·∫£
                    result_filename = f"age_result_{timestamp}.jpg"
                    cv2.imwrite(result_filename, result_image)
                    print(f"üíæ ƒê√£ l∆∞u k·∫øt qu·∫£: {result_filename}")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    cv2.imshow('Age Analysis Result', result_image)
                    print("\nüëÅÔ∏è Nh·∫•n ph√≠m b·∫•t k·ª≥ ƒë·ªÉ ti·∫øp t·ª•c...")
                    cv2.waitKey(0)
                    cv2.destroyWindow('Age Analysis Result')
                
                # H·ªèi c√≥ mu·ªën ch·ª•p ti·∫øp
                choice = input("\nüì∑ Ch·ª•p ·∫£nh kh√°c? (y/n): ").strip().lower()
                if choice != 'y':
                    break
                    
            elif key == 27:  # ESC
                break
        
        cap.release()
        cv2.destroyAllWindows()

def main():
    print("üéØ Ph√¢n t√≠ch ƒê·ªô tu·ªïi t·ª´ Khu√¥n m·∫∑t")
    print("=" * 50)
    
    analyzer = AgeAnalyzer()
    
    while True:
        print("\nüìã Ch·ªçn ch·∫ø ƒë·ªô:")
        print("1. üì∏ Ch·ª•p ·∫£nh v√† ph√¢n t√≠ch tu·ªïi")
        print("2. üìÅ Ph√¢n t√≠ch ·∫£nh c√≥ s·∫µn")
        print("3. üìä Ph√¢n t√≠ch h√†ng lo·∫°t")
        print("4. ‚ùå Tho√°t")
        
        choice = input("\nüëâ Nh·∫≠p l·ª±a ch·ªçn (1-4): ").strip()
        
        if choice == '1':
            analyzer.capture_and_analyze()
            
        elif choice == '2':
            # Li·ªát k√™ ·∫£nh c√≥ s·∫µn
            image_files = [f for f in os.listdir('.') if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
            
            if image_files:
                print("\nüì∑ ·∫¢nh c√≥ s·∫µn:")
                for i, file in enumerate(image_files):
                    print(f"   {i+1}. {file}")
                
                try:
                    idx = int(input(f"\nCh·ªçn ·∫£nh (1-{len(image_files)}): ")) - 1
                    if 0 <= idx < len(image_files):
                        filename = image_files[idx]
                        result_image, results = analyzer.analyze_image(filename)
                        
                        if results:
                            # Hi·ªÉn th·ªã k·∫øt qu·∫£
                            cv2.imshow('Age Analysis Result', result_image)
                            print("\nüëÅÔ∏è Nh·∫•n ph√≠m b·∫•t k·ª≥ ƒë·ªÉ ƒë√≥ng...")
                            cv2.waitKey(0)
                            cv2.destroyAllWindows()
                            
                            # L∆∞u k·∫øt qu·∫£
                            save = input("\nüíæ L∆∞u k·∫øt qu·∫£? (y/n): ").strip().lower()
                            if save == 'y':
                                result_filename = f"age_analyzed_{datetime.now().strftime('%H%M%S')}.jpg"
                                cv2.imwrite(result_filename, result_image)
                                print(f"‚úÖ ƒê√£ l∆∞u: {result_filename}")
                    else:
                        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
                except ValueError:
                    print("‚ùå Vui l√≤ng nh·∫≠p s·ªë!")
            else:
                filename = input("üì∑ Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: ").strip()
                if os.path.exists(filename):
                    analyzer.analyze_image(filename)
                else:
                    print("‚ùå File kh√¥ng t·ªìn t·∫°i!")
        
        elif choice == '3':
            print("üìä T√≠nh nƒÉng ph√¢n t√≠ch h√†ng lo·∫°t s·∫Ω ƒë∆∞·ª£c b·ªï sung...")
            
        elif choice == '4':
            print("üëã T·∫°m bi·ªát!")
            break
            
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")

if __name__ == "__main__":
    main()
