import cv2
import numpy as np
import streamlit as st
from PIL import Image
import tempfile
import os

class FaceAgeDetector:
    def __init__(self):
        """Kh·ªüi t·∫°o detector v·ªõi c√°c model pre-trained"""
        # T·∫£i model ph√°t hi·ªán khu√¥n m·∫∑t
        self.face_net = cv2.dnn.readNetFromTensorflow('models/opencv_face_detector_uint8.pb', 
                                                      'models/opencv_face_detector.pbtxt')
        
        # T·∫£i model ∆∞·ªõc t√≠nh ƒë·ªô tu·ªïi
        self.age_net = cv2.dnn.readNetFromCaffe('models/age_deploy.prototxt', 
                                                'models/age_net.caffemodel')
        
        # Danh s√°ch c√°c nh√≥m tu·ªïi
        self.age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', 
                        '(38-43)', '(48-53)', '(60-100)']
        
        # C·∫•u h√¨nh
        self.conf_threshold = 0.7
        
    def detect_faces(self, image):
        """Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh"""
        (h, w) = image.shape[:2]
        
        # T·∫°o blob t·ª´ ·∫£nh
        blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123])
        
        # ƒê∆∞a blob v√†o network
        self.face_net.setInput(blob)
        detections = self.face_net.forward()
        
        faces = []
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            
            if confidence > self.conf_threshold:
                x1 = int(detections[0, 0, i, 3] * w)
                y1 = int(detections[0, 0, i, 4] * h)
                x2 = int(detections[0, 0, i, 5] * w)
                y2 = int(detections[0, 0, i, 6] * h)
                
                faces.append([x1, y1, x2, y2])
                
        return faces
    
    def predict_age(self, face_img):
        """D·ª± ƒëo√°n ƒë·ªô tu·ªïi t·ª´ ·∫£nh khu√¥n m·∫∑t"""
        blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), 
                                    (78.4263377603, 87.7689143744, 114.895847746), 
                                    swapRB=False)
        
        self.age_net.setInput(blob)
        age_preds = self.age_net.forward()
        age_index = age_preds[0].argmax()
        
        return self.age_list[age_index]
    
    def process_image(self, image):
        """X·ª≠ l√Ω ·∫£nh: ph√°t hi·ªán khu√¥n m·∫∑t v√† ∆∞·ªõc t√≠nh ƒë·ªô tu·ªïi"""
        # Chuy·ªÉn ƒë·ªïi sang RGB n·∫øu c·∫ßn
        if len(image.shape) == 3:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image_rgb = image
            
        # Ph√°t hi·ªán khu√¥n m·∫∑t
        faces = self.detect_faces(image)
        
        results = []
        for (x1, y1, x2, y2) in faces:
            # C·∫Øt khu√¥n m·∫∑t
            face = image[y1:y2, x1:x2]
            
            if face.size > 0:
                # D·ª± ƒëo√°n ƒë·ªô tu·ªïi
                age = self.predict_age(face)
                results.append({
                    'bbox': (x1, y1, x2, y2),
                    'age': age
                })
                
                # V·∫Ω bounding box v√† tu·ªïi
                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(image, f'Age: {age}', (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        return image, results

def download_models():
    """T·∫£i xu·ªëng c√°c model c·∫ßn thi·∫øt"""
    import urllib.request
    
    # T·∫°o th∆∞ m·ª•c models n·∫øu ch∆∞a c√≥
    if not os.path.exists('models'):
        os.makedirs('models')
    
    models = {
        'opencv_face_detector_uint8.pb': 'https://github.com/opencv/opencv_3rdparty/raw/dnn_samples_face_detector_20170830/opencv_face_detector_uint8.pb',
        'opencv_face_detector.pbtxt': 'https://github.com/opencv/opencv/raw/master/samples/dnn/face_detector/opencv_face_detector.pbtxt',
        'age_deploy.prototxt': 'https://github.com/GilLevi/AgeGenderDeepLearning/raw/master/age_deploy.prototxt',
        'age_net.caffemodel': 'https://github.com/GilLevi/AgeGenderDeepLearning/raw/master/age_net.caffemodel'
    }
    
    for filename, url in models.items():
        filepath = f'models/{filename}'
        if not os.path.exists(filepath):
            st.info(f'ƒêang t·∫£i xu·ªëng {filename}...')
            try:
                urllib.request.urlretrieve(url, filepath)
                st.success(f'ƒê√£ t·∫£i xu·ªëng {filename}')
            except Exception as e:
                st.error(f'L·ªói khi t·∫£i {filename}: {str(e)}')
                return False
    
    return True

def main():
    st.set_page_config(
        page_title="·ª®ng d·ª•ng Nh·∫≠n di·ªán Tu·ªïi",
        page_icon="üë§",
        layout="wide"
    )
    
    st.title("üéØ ·ª®ng d·ª•ng Nh·∫≠n di·ªán Khu√¥n m·∫∑t v√† ∆Ø·ªõc t√≠nh ƒê·ªô tu·ªïi")
    st.markdown("---")
    
    # Sidebar
    st.sidebar.title("‚öôÔ∏è C√†i ƒë·∫∑t")
    
    # Ki·ªÉm tra v√† t·∫£i models
    if not all(os.path.exists(f'models/{f}') for f in ['opencv_face_detector_uint8.pb', 
                                                       'opencv_face_detector.pbtxt',
                                                       'age_deploy.prototxt', 
                                                       'age_net.caffemodel']):
        st.warning("‚ö†Ô∏è C·∫ßn t·∫£i xu·ªëng c√°c model c·∫ßn thi·∫øt")
        if st.button("üì• T·∫£i xu·ªëng Models"):
            if download_models():
                st.success("‚úÖ ƒê√£ t·∫£i xu·ªëng t·∫•t c·∫£ models!")
                st.experimental_rerun()
        return
    
    # Kh·ªüi t·∫°o detector
    try:
        detector = FaceAgeDetector()
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o detector: {str(e)}")
        return
    
    # Ch·ªçn ngu·ªìn input
    input_type = st.sidebar.selectbox(
        "üì∑ Ch·ªçn ngu·ªìn ·∫£nh:",
        ["Camera tr·ª±c ti·∫øp", "T·∫£i ·∫£nh l√™n", "·∫¢nh m·∫´u"]
    )
    
    if input_type == "Camera tr·ª±c ti·∫øp":
        st.subheader("üìπ Camera tr·ª±c ti·∫øp")
        
        # T·∫°o placeholder cho video
        video_placeholder = st.empty()
        
        # N√∫t b·∫Øt ƒë·∫ßu/d·ª´ng camera
        col1, col2 = st.columns(2)
        
        with col1:
            start_camera = st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu Camera")
        
        with col2:
            stop_camera = st.button("‚èπÔ∏è D·ª´ng Camera")
        
        if start_camera:
            cap = cv2.VideoCapture(0)
            
            if not cap.isOpened():
                st.error("‚ùå Kh√¥ng th·ªÉ m·ªü camera!")
                return
            
            # Session state ƒë·ªÉ ƒëi·ªÅu khi·ªÉn camera
            if 'camera_running' not in st.session_state:
                st.session_state.camera_running = True
            
            while st.session_state.camera_running:
                ret, frame = cap.read()
                
                if not ret:
                    st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera!")
                    break
                
                # X·ª≠ l√Ω frame
                processed_frame, results = detector.process_image(frame.copy())
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                video_placeholder.image(processed_frame_rgb, channels="RGB", use_column_width=True)
                
                # Hi·ªÉn th·ªã th√¥ng tin
                if results:
                    info_text = f"üîç Ph√°t hi·ªán {len(results)} khu√¥n m·∫∑t: "
                    for i, result in enumerate(results):
                        info_text += f"Ng∆∞·ªùi {i+1}: {result['age']} tu·ªïi "
                    st.info(info_text)
            
            cap.release()
        
        if stop_camera:
            st.session_state.camera_running = False
    
    elif input_type == "T·∫£i ·∫£nh l√™n":
        st.subheader("üì§ T·∫£i ·∫£nh l√™n")
        
        uploaded_file = st.file_uploader(
            "Ch·ªçn ·∫£nh ƒë·ªÉ ph√¢n t√≠ch:",
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="H·ªó tr·ª£ c√°c ƒë·ªãnh d·∫°ng: JPG, JPEG, PNG, BMP"
        )
        
        if uploaded_file is not None:
            # ƒê·ªçc ·∫£nh
            image = Image.open(uploaded_file)
            image_np = np.array(image)
            
            # Chuy·ªÉn ƒë·ªïi RGB sang BGR cho OpenCV
            if len(image_np.shape) == 3:
                image_cv = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
            else:
                image_cv = image_np
            
            # Hi·ªÉn th·ªã ·∫£nh g·ªëc
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üì∑ ·∫¢nh g·ªëc")
                st.image(image, use_column_width=True)
            
            # X·ª≠ l√Ω ·∫£nh
            with st.spinner("üîÑ ƒêang ph√¢n t√≠ch..."):
                processed_image, results = detector.process_image(image_cv)
                processed_image_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
            
            with col2:
                st.subheader("üéØ K·∫øt qu·∫£ ph√¢n t√≠ch")
                st.image(processed_image_rgb, use_column_width=True)
            
            # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt
            if results:
                st.success(f"‚úÖ Ph√°t hi·ªán {len(results)} khu√¥n m·∫∑t!")
                
                for i, result in enumerate(results):
                    st.info(f"üë§ **Ng∆∞·ªùi {i+1}:** ƒê·ªô tu·ªïi ∆∞·ªõc t√≠nh **{result['age']}**")
            else:
                st.warning("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o trong ·∫£nh!")
    
    else:  # ·∫¢nh m·∫´u
        st.subheader("üñºÔ∏è ·∫¢nh m·∫´u")
        st.info("üí° T√≠nh nƒÉng n√†y s·∫Ω ƒë∆∞·ª£c b·ªï sung trong phi√™n b·∫£n ti·∫øp theo")

if __name__ == "__main__":
    main()
